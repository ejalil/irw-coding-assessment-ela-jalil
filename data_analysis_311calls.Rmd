---
title: "Data Analysis 311 calls"
author: "Ela Jalil"
date: "2026-01-20"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Part 1: Data acquisition and cleaning

Load libraries

```{r}
library(tidyverse)
library(janitor)
library(dplyr)
library(DT)
library(lubridate)
library(tidyr)
library(leaflet)
```

Import 311 data sets from 2015-2024, standardize titles, and initial cleaning of data

```{r}
call_2015<- read.csv("data/All_Service_Requests_-_2015.csv") %>% 
  clean_names()
call_2016 <- read.csv("data/All_Service_Requests_-_2016.csv") %>% 
  clean_names()
call_2017 <- read.csv("data/311_City_Service_Requests_in_2017.csv") %>% 
  clean_names()
call_2018 <-read.csv("data/311_City_Service_Requests_in_2018.csv") %>% 
  clean_names()
call_2019 <- read.csv("data/311_City_Service_Requests_in_2019.csv") %>% 
  clean_names()
call_2020<- read.csv("data/All_Service_Requests_-_2020.csv") %>% 
  clean_names()
call_2021 <- read.csv("data/311_City_Service_Requests_in_2021.csv") %>% 
  clean_names()
call_2022 <- read.csv("data/311_City_Service_Requests_in_2022.csv") %>% 
  clean_names()
call_2023 <- read.csv("data/All_Service_Requests_-_2023.csv") %>% 
  clean_names()
call_2024 <- read.csv("data/All_Service_Requests_-_2024.csv") %>% 
  clean_names()
```

Figure out what columns are necessary to keep

```{r}
head(call_2015)
```

Get rid of repetitive information within the data

```{r}
#adddate and serviceorderdate are the same, along with x and x coordinate etc. I will also get rid of city and state, because we know where the data is coming from. I am also getting rid of the rows created, edited and se_anno_cad_data, and object ID because it is not included in the original meta data.

clean_2015 <- select(call_2015, -c(1, 2,5,6,14,20,22,30,31,32,33))
#repeat this process for all data sets with adjustments
clean_2016 <- select(call_2016, -c(1, 2,5,6,14,18,19,20,22,30,31,32,33))
clean_2017 <- select(call_2017, -c(1, 2,5,6,14,18,19,20,22,30,31,32,33,34))
clean_2018 <- select(call_2018, -c(1, 2,5,6,14,18,19,20,22,30,31,32,33,34))
clean_2019 <- select(call_2019, -c(1, 2,5,6,14,18,19,20,22,30,31,32,33,34))
clean_2020 <- select(call_2020, -c(1, 2,5,6,14,18,19,20,22,30,31,32,33,34))
clean_2021 <- select(call_2021, -c(1, 2,5,6,14,18,19,20,22,30,31,32,33,34))
clean_2022 <- select(call_2022, -c(1, 2,5,6,14,18,19,20,22,30,31,32,33,34))
clean_2023 <- select(call_2023, -c(1, 2,5,6,14,18,19,20,22,30,31,32,33,34))
clean_2024 <- select(call_2024, -c(1, 2,5,6,14,18,20,21,22,30,31,32,33,34))
```

## Part 2: Exploring

Now that I have 10 cleaned data sets, I will first explore the 2024 data set, and then see if the trends carry through the data

```{r}
nrow(clean_2024)
#There were 422,321 calls in 2024. This will be compared with the other years in a bar chart.
nrow(clean_2023)
#There were 423,243 calls in 2023.
nrow(clean_2022)
#There were 386,740 calls in 2022. 
nrow(clean_2021)
#There were 360,827 calls in 2021. 
nrow(clean_2020)
#There were 305,561 calls in 2020.
nrow(clean_2019)
#There were 367,099 calls in 2019
nrow(clean_2018)
#There were 338,832 calls in 2018.
nrow(clean_2017)
#There were 311,521 calls in 2017.
nrow(clean_2016)
#There were 304,474 calls in 2016.
nrow(clean_2015)
#There were 298,414 calls in 2015. 
#2023 had the most 311 calls over the past 10 years. 
#422321-298414=123,907
#There was over a 100,000 call difference between 2024 and 2015. Initial question: have more problems popped up over the years, or do more people utilize the service now?


```

Finding the most common zip codes that are calling 311 calls in 2024

```{r}
clean_2024 %>% 
  group_by(zipcode) %>% 
  count() %>% 
  arrange(desc(n))
#Zipcodes 20002 (6,0096 calls), 20011(46,137 calls), 20001 (33,959 calls), 20019 (33,188 calls) and 20003 (27,582 calls) had the highest concentration of 311 calls in 2024. I would like to see how closely located these zipcodes are, and what the poverty/population breakdown of those areas are. 

```
